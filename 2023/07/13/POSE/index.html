<!DOCTYPE html>
<html lang="en">
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0,  viewport-fit=cover" name="viewport" />
    <meta name="description" content="POSE" />
    <meta name="hexo-theme-A4" content="v1.6.9" />
    <link rel="alternate icon" type="image/webp" href="/img/favicon.webp">
    <title>hwan | </title>

    
        
            
<link rel="stylesheet" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/reset.css">

            
<link rel="stylesheet" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/markdown.css">

            
<link rel="stylesheet" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/fonts.css">
 
            <!--注意：首页既不是post也不是page-->
            
        
    
    
<link rel="stylesheet" href="/css/ui.css">
 
    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.3.0"></head>
    
    <body>
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    
<div class="header">
    <div class="header-container">
        <img style="
        width: 56px;
        height: auto;" alt="^-^" cache-control="max-age=86400" class="header-img" src="/img/favicon.webp" width="10%"></img>
        <div class="header-content">
            <a class="logo" href="/">hwan</a> 
            <span class="description"></span> 
        </div>
        
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">首页</a></li>
            
        
            
                <li><a href="/list/">文章</a></li>
            
        
            
                <li><a href="/about/">关于</a></li>
            
        
            
                <li><a href="/tags/">标签</a></li>
            
        
            
                <li><a href="/categories/">分类</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--说明是文章post页面-->
                    
                        <div class="post-main">

    
        <div class="post-main-title">
            POSE
        </div>
      
    

    <div class="post-md">
        
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#RLE"><span class="post-toc-text">RLE</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#FLow%E6%9D%8E%E5%AE%8F%E6%AF%85"><span class="post-toc-text">FLow李宏毅</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E4%B8%8E%E5%A7%BF%E6%80%81%E7%9B%B8%E5%85%B3%E7%9A%84%E8%AE%BA%E6%96%87%E4%B8%BB%E8%A6%81%E7%9C%8B%E6%95%B0%E6%8D%AE%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84"><span class="post-toc-text">与姿态相关的论文主要看数据组织结构</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#DAS"><span class="post-toc-text">DAS</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#voxel-pose"><span class="post-toc-text">voxel_pose</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#PCT"><span class="post-toc-text">PCT</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#GFPose"><span class="post-toc-text">GFPose</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%A7%BF%E6%80%81%E7%9B%B8%E5%85%B3%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="post-toc-text">姿态相关的评价指标</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3D-Percentage-of-Correct-Keypoints"><span class="post-toc-text">3D Percentage of Correct Keypoints</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#PCK-rel"><span class="post-toc-text">PCK_rel</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#PCK-abs"><span class="post-toc-text">PCK_abs</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%A7%BF%E6%80%81%E7%9B%B8%E5%85%B3%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="post-toc-text">姿态相关的数据</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#CrowdPose"><span class="post-toc-text">CrowdPose</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#OCHuman"><span class="post-toc-text">OCHuman</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#SyncOCC"><span class="post-toc-text">SyncOCC</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MPII"><span class="post-toc-text">MPII</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#CMU-Panoptic"><span class="post-toc-text">CMU Panoptic</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"><span class="post-toc-text">使用方法</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#COCO-keypoint%E6%95%B0%E6%8D%AE"><span class="post-toc-text">COCO keypoint数据</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MuPoTS"><span class="post-toc-text">MuPoTS</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MuCo"><span class="post-toc-text">MuCo</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MPI-INF-3DHP"><span class="post-toc-text">MPI-INF-3DHP</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Human-3-6%E4%BD%BF%E7%94%A8"><span class="post-toc-text">Human 3.6使用</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%95%B0%E6%8D%AE%E6%A0%87%E7%AD%BE%E6%A0%BC%E5%BC%8F"><span class="post-toc-text">数据标签格式</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#json-RLE-%EF%BC%9A"><span class="post-toc-text">json(RLE)：</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#POSENET%E7%BB%84%E7%BB%87%E6%A0%BC%E5%BC%8F"><span class="post-toc-text">POSENET组织格式</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#RLE%E7%BB%84%E7%BB%87%E6%A0%BC%E5%BC%8F"><span class="post-toc-text">RLE组织格式</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%AD%A6%E4%B9%A0RLE%E4%BB%A3%E7%A0%81"><span class="post-toc-text">学习RLE代码</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Train-on-MSCOCO"><span class="post-toc-text">Train on MSCOCO</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%86%99%E4%BB%A3%E7%A0%81%E7%9A%84%E6%8A%80%E5%B7%A7"><span class="post-toc-text">写代码的技巧</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#opt-snapshot"><span class="post-toc-text">opt.snapshot</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E2%80%98pytorch%E2%80%99-%E2%80%98slurm%E2%80%99-%E2%80%98mpi%E2%80%99%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0"><span class="post-toc-text">‘pytorch’, ‘slurm’, ‘mpi’分布式平台</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%AF%B9%E4%BA%8E%E6%9F%90%E4%BA%9B%E6%A8%A1%E5%9D%97%E7%9A%84%E7%89%B9%E5%AE%9A%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="post-toc-text">对于某些模块的特定初始化</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%B3%A8%E5%86%8C%E5%99%A8%E7%B1%BB%E4%BC%BC%E4%BA%8Emmcv"><span class="post-toc-text">注册器类似于mmcv</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%8D%9F%E5%A4%B1%E7%B1%BB%E5%9E%8B"><span class="post-toc-text">损失类型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#MSELoss"><span class="post-toc-text">MSELoss</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#RLELoss"><span class="post-toc-text">RLELoss</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#RLELoss3D"><span class="post-toc-text">RLELoss3D</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#SimpleTransform3D-object"><span class="post-toc-text">SimpleTransform3D(object):</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#dataloader"><span class="post-toc-text">dataloader</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#class-H36m-data-Dataset"><span class="post-toc-text">class H36m(data.Dataset):</span></a></li></ol></li></ol></li></ol></li></ol>
        
        <h1 id="RLE"><a href="#RLE" class="headerlink" title="RLE"></a>RLE</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/625023463">https://zhuanlan.zhihu.com/p/625023463</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/440567782">https://zhuanlan.zhihu.com/p/440567782</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/429017412">https://zhuanlan.zhihu.com/p/429017412</a> 讲的最好的文章</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Jeff-sjtu/res-loglikelihood-regression">https://github.com/Jeff-sjtu/res-loglikelihood-regression</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV18E411w7Jh/?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV18E411w7Jh/?spm_id_from=333.999.0.0</a> 讲flow的视频</p>
<p>GAN训练：模式崩溃和后置崩溃挑战</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/165577850">https://zhuanlan.zhihu.com/p/165577850</a> flow的文章</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59615785">https://zhuanlan.zhihu.com/p/59615785</a> 讲flow的文章</p>
<pre><code>20个采样点 10个实列
all number of params: 43108693
number of backbone params: 33841352
其余的9267341
</code></pre>
<pre><code>20个采样点 5个实列
all number of params: 43105908
number of backbone params: 33841352
</code></pre>
<pre><code>10个采样点 5个实列
all number of params: 42365748
number of backbone params: 33841352
</code></pre>
<p>19416917</p>
<p>尺寸不变</p>
<pre><code>kernel_size=3, padding=1, stride=1 
kernel_size=5, padding=2, stride=1
kernel_size=7, padding=3, stride=1
</code></pre>
<h2 id="FLow李宏毅"><a href="#FLow李宏毅" class="headerlink" title="FLow李宏毅"></a>FLow李宏毅</h2><p><img src="/../images/POSE/image-20230729160629435.png" alt="image-20230729160629435"></p>
<p><img src="/../images/POSE/image-20230729160949339.png" alt="image-20230729160949339"></p>
<p><img src="/../images/POSE/image-20230729161134206.png" alt="image-20230729161134206"></p>
<p><img src="/../images/POSE/image-20230729161440156.png" alt="image-20230729161440156"></p>
<p><img src="/../images/POSE/image-20230729162505660.png" alt="image-20230729162505660"></p>
<p><img src="/../images/POSE/image-20230729162738281.png" alt="image-20230729162738281"></p>
<p>normal flow训练过程</p>
<p><img src="/../images/POSE/image-20230729163112817.png" alt="image-20230729163112817"></p>
<p><img src="/../images/POSE/image-20230729163827285.png" alt="image-20230729163827285"></p>
<p><img src="/../images/POSE/image-20230729163844115.png" alt="image-20230729163844115"></p>
<p><img src="/../images/POSE/image-20230729164002842.png" alt="image-20230729164002842"></p>
<h1 id="与姿态相关的论文主要看数据组织结构"><a href="#与姿态相关的论文主要看数据组织结构" class="headerlink" title="与姿态相关的论文主要看数据组织结构"></a>与姿态相关的论文主要看数据组织结构</h1><h2 id="DAS"><a href="#DAS" class="headerlink" title="DAS"></a>DAS</h2><pre><code>$&#123;ROOT&#125;
|-- data
|   |-- panoptic
|   |   |-- 160226_haggling1
|   |   |   |-- hdImgs
|   |   |   |   |-- 00_16
|   |   |   |   |-- 00_30
|   |   |-- 160422_haggling1
|   |   |-- 160226_mafia1
|   |   |-- 160422_mafia2
|   |   |-- 160226_ultimatum1
|   |   |-- 160422_ultimatum1
|   |   |-- 160906_pizza1
|   |   |-- annotations
|   |   |   |-- train.json
|   |   |   |-- haggling.json
|   |   |   |-- mafia.json
|   |   |   |-- ultimatum.json
|   |   |   |-- pizza.json
|   |-- coco
|   |   |-- train2017
|   |   |-- annotations
|   |   |   |-- person_keypoints_train2017.json
|   |-- muco
|   |   |-- unaugmented_set
|   |   |-- augmented_set
|   |   |-- annotations
|   |   |   |-- train_all_interv1.json
|   |-- mupots
|   |   |-- TS1
|   |   |   |-- img_000000.jpg
|   |   |   |-- ...
|   |   |-- ...
|   |   |-- TS20
|   |   |-- annotations
|   |   |   |-- MuPoTS-3D.json
</code></pre>
<h2 id="voxel-pose"><a href="#voxel-pose" class="headerlink" title="voxel_pose"></a>voxel_pose</h2><pre><code>$&#123;POSE_ROOT&#125;
|-- models
|   |-- pose_resnet50_panoptic.pth.tar
|-- data
    |-- panoptic-toolbox
        |-- data
            |-- 16060224_haggling1
            |   |-- hdImgs
            |   |-- hdvideos
            |   |-- hdPose3d_stage1_coco19
            |   |-- calibration_160224_haggling1.json
            |-- 160226_haggling1  
            |-- ...
</code></pre>
<h2 id="PCT"><a href="#PCT" class="headerlink" title="PCT"></a>PCT</h2><pre><code>$&#123;POSE_ROOT&#125;
|-- data
`-- |-- coco
    `-- |-- annotations
        |   |-- person_keypoints_train2017.json
        |   `-- person_keypoints_val2017.json
        |-- person_detection_results
        |   |-- COCO_val2017_detections_AP_H_56_person.json
        |   |-- COCO_test-dev2017_detections_AP_H_609_person.json
        `-- images
            |-- train2017
            |   |-- 000000000009.jpg
            |   |-- 000000000025.jpg
            |   |-- 000000000030.jpg
            |   |-- ... 
            `-- val2017
                |-- 000000000139.jpg
                |-- 000000000285.jpg
                |-- 000000000632.jpg
                |-- ... 
</code></pre>
<h2 id="GFPose"><a href="#GFPose" class="headerlink" title="GFPose"></a>GFPose</h2><pre><code>$&#123;POSE_ROOT&#125;
|-- configs
|-- lib
|-- run
|-- checkpoint
    |-- u3d
        |-- best_model.pth
|-- data
    |-- h36m
        |-- h36m_train.pkl
        |-- h36m_test.pkl
        |-- h36m_sh_dt_ft.pkl
</code></pre>
<h1 id="姿态相关的评价指标"><a href="#姿态相关的评价指标" class="headerlink" title="姿态相关的评价指标"></a>姿态相关的评价指标</h1><h2 id="3D-Percentage-of-Correct-Keypoints"><a href="#3D-Percentage-of-Correct-Keypoints" class="headerlink" title="3D Percentage of Correct Keypoints"></a>3D Percentage of Correct Keypoints</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/StupidAutofan/article/details/125436224">https://blog.csdn.net/StupidAutofan/article/details/125436224</a></p>
<h2 id="PCK-rel"><a href="#PCK-rel" class="headerlink" title="PCK_rel"></a>PCK_rel</h2><p>对齐后的坐标系</p>
<h2 id="PCK-abs"><a href="#PCK-abs" class="headerlink" title="PCK_abs"></a>PCK_abs</h2><p>0号相机对应的坐标系</p>
<h1 id="姿态相关的数据"><a href="#姿态相关的数据" class="headerlink" title="姿态相关的数据"></a>姿态相关的数据</h1><h2 id="CrowdPose"><a href="#CrowdPose" class="headerlink" title="CrowdPose"></a>CrowdPose</h2><h2 id="OCHuman"><a href="#OCHuman" class="headerlink" title="OCHuman"></a>OCHuman</h2><h2 id="SyncOCC"><a href="#SyncOCC" class="headerlink" title="SyncOCC"></a>SyncOCC</h2><p>合成的数据</p>
<h2 id="MPII"><a href="#MPII" class="headerlink" title="MPII"></a>MPII</h2><p>The dataset includes around <strong>25K images</strong> containing over <strong>40K people</strong> with annotated body joints；</p>
<p><strong>410 human activities</strong> and each image is provided with an activity label；</p>
<p>POSENET也有下载链接，组织为</p>
<pre><code>|   |-- MPII
|   |   |-- images
|   |   |-- annotations
</code></pre>
<p>官网也有</p>
<p><a target="_blank" rel="noopener" href="http://human-pose.mpi-inf.mpg.de/#download">http://human-pose.mpi-inf.mpg.de/#download</a></p>
<h2 id="CMU-Panoptic"><a href="#CMU-Panoptic" class="headerlink" title="CMU Panoptic"></a>CMU Panoptic</h2><p><a target="_blank" rel="noopener" href="http://domedb.perception.cs.cmu.edu/">http://domedb.perception.cs.cmu.edu/</a> 数据主页</p>
<p><a target="_blank" rel="noopener" href="https://github.com/CMU-Perceptual-Computing-Lab/panoptic-toolbox">https://github.com/CMU-Perceptual-Computing-Lab/panoptic-toolbox</a></p>
<p>31个 多视角HD video（高清视频）通常指 1080p（1920x1080 像素）或更高分辨率的视频。</p>
<h6 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h6><p>下载这个PanopticStudio Toolbox，然后</p>
<pre><code>./scripts/getData.sh 171204_pose1_sample 举列子
./scripts/getData.sh 171204_pose1

./scripts/getData.sh (sequenceName) (VGA_Video_Number) (HD_Video_Number)
列如./scripts/getData.sh 171204_pose1_sample 240 10 
240 vga videos and 10 videos.

可选的序列名称
https://docs.google.com/spreadsheets/d/1eoe74dHRtoMVVFLKCTJkAtF8zqxAnoo2Nt15CYYvHEE/edit#gid=1333444170

./scripts/getDB_panopticHD_ver1_2.sh
下载1.2数据版本所有数据
上述命令默认是不下载视频数据的，就要像上面一样指定视频个数

假如说现在下载好了视频，需要将视频变成每一帧每一帧的，然后将一视频的标签也变成一帧一帧图片对应的pose;注需要ffmpeg
运行这个命令有
./scripts/extractAll.sh 171204_pose1_sample
171204_pose1_sample/hdImgs/00_00/00_00_00000000.jpg
171204_pose1_sample/hdPose3d_stage1_coco19/body3DScene_00000000.json

在这个工具里面有一些可视化的代码，以及从3D重投影到2D的方法
还有一些kinect数据点云的

注：https://github.com/wangzt-halo/das在DAS这个项目有一个代码可以将原始标签转化
</code></pre>
<p>480 views VGA video（标准视频）是指分辨率为 640x480 像素的视频。</p>
<ul>
<li>171204_pose1_sample&#x2F;hdVideos&#x2F;hd_00_XX.mp4  #synchronized HD video files (31 views)</li>
<li>171204_pose1_sample&#x2F;vgaVideos&#x2F;KINECTNODE%d&#x2F;vga_XX_XX.mp4 #synchrponized VGA video files (480 views)</li>
<li>171204_pose1_sample&#x2F;calibration_171204_pose1_sample.json #calibration files</li>
<li>171204_pose1_sample&#x2F;hdPose3d_stage1_coco19.tar #3D Body Keypoint Data (coco19 keypoint definition)</li>
<li>171204_pose1_sample&#x2F;hdFace3d.tar #3D Face Keypoint Data</li>
<li>171204_pose1_sample&#x2F;hdHand3d.tar #3D Hand Keypoint Data</li>
</ul>
<h2 id="COCO-keypoint数据"><a href="#COCO-keypoint数据" class="headerlink" title="COCO keypoint数据"></a>COCO keypoint数据</h2><p>150K训练5K验证30K测试</p>
<img src="../images/POSE/image-20230721142637523.png" alt="image-20230721142637523" style="zoom:80%;" />

<img src="../images/POSE/image-20230721142828338.png" alt="image-20230721142828338" style="zoom:50%;" />

<img src="../images/POSE/image-20230721142920961.png" alt="image-20230721142920961" style="zoom:80%;" />



<h2 id="MuPoTS"><a href="#MuPoTS" class="headerlink" title="MuPoTS"></a>MuPoTS</h2><p>20 video sequences,Each video has up to 3 subjects.</p>
<p>POSENET组织格式</p>
<p>POSENET也有下载链接</p>
<pre><code>|   |-- MuPoTS
|   |   |-- bbox_root
|   |   |   |-- bbox_mupots_output.json
|   |   |-- data
|   |   |   |-- MultiPersonTestSet
|   |   |   |-- MuPoTS-3D.json
</code></pre>
<h2 id="MuCo"><a href="#MuCo" class="headerlink" title="MuCo"></a>MuCo</h2><p>这些图像是通过从单人 3D 姿态估计数据集 MPI-INF-3DHP [19] 中随机合成人来生成的。</p>
<p>POSENET组织格式</p>
<p>POSENET也有下载链接</p>
<pre><code>|   |-- MuCo
|   |   |-- data
|   |   |   |-- augmented_set
|   |   |   |-- unaugmented_set
|   |   |   |-- MuCo-3DHP.json
</code></pre>
<h2 id="MPI-INF-3DHP"><a href="#MPI-INF-3DHP" class="headerlink" title="MPI-INF-3DHP"></a>MPI-INF-3DHP</h2><h2 id="Human-3-6使用"><a href="#Human-3-6使用" class="headerlink" title="Human 3.6使用"></a>Human 3.6使用</h2><p>7 个场景 讨论、吸烟、拍照以及打电话等等）</p>
<h3 id="数据标签格式"><a href="#数据标签格式" class="headerlink" title="数据标签格式"></a>数据标签格式</h3><pre><code>
    Pelvis（骨盆）
    R_Hip（右髋）
    R_Knee（右膝）
    R_Ankle（右踝）
    L_Hip（左髋）
    L_Knee（左膝）
    L_Ankle（左踝）
    Torso（躯干）
    Neck（颈部）
    Nose（鼻子）
    Head（头部）
    L_Shoulder（左肩）
    L_Elbow（左肘）
    L_Wrist（左腕）
    R_Shoulder（右肩）
    R_Elbow（右肘）
    R_Wrist（右腕）
    Thorax（胸部）
</code></pre>
<h4 id="json-RLE-："><a href="#json-RLE-：" class="headerlink" title="json(RLE)："></a>json(RLE)：</h4><img src="../images/POSE/image-20230727144953267.png" alt="image-20230727144953267" style="zoom:80%;" />

<p>这里的action_name对应action_idx</p>
<p> action_name &#x3D; [‘Directions’, ‘Discussion’, ‘Eating’, ‘Greeting’, ‘Phoning’, ‘Posing’, ‘Purchases’,</p>
<p>​          ‘Sitting’, ‘SittingDown’, ‘Smoking’, ‘Photo’, ‘Waiting’, ‘Walking’, ‘WalkDog’, ‘WalkTogether’]</p>
<p>关于相机标定参数:</p>
<p>R是3*3的矩阵，</p>
<p>t是3*1的矩阵</p>
<p>f,c是2*1的矩阵</p>
<p><img src="/../images/POSE/image-20230727145435923.png" alt="image-20230727145435923"></p>
<p>世界坐标系下的关键点个数是18,3</p>
<img src="../images/POSE/image-20230727145519612.png" alt="image-20230727145519612" style="zoom:50%;" />



<img src="../images/POSE/image-20230727145553510.png" alt="image-20230727145553510" style="zoom:50%;" />

<img src="../images/POSE/image-20230727145617817.png" alt="image-20230727145617817" style="zoom:50%;" />



<p>这里的bbox是xywh</p>
<img src="../images/POSE/image-20230727145635388.png" alt="image-20230727145635388" style="zoom:50%;" />





<p>原始数据下载</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42951560/article/details/126380971">https://blog.csdn.net/qq_42951560/article/details/126380971</a></p>
<h3 id="POSENET组织格式"><a href="#POSENET组织格式" class="headerlink" title="POSENET组织格式"></a>POSENET组织格式</h3><p>POSENET也有下载链接</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mks0601/3DMPPE_POSENET_RELEASE">https://github.com/mks0601/3DMPPE_POSENET_RELEASE</a></p>
<pre><code>|   |-- Human36M
|   |   |-- bbox_root
|   |   |   |-- bbox_root_human36m_output.json
|   |   |-- images
|   |   |-- annotations
</code></pre>
<h3 id="RLE组织格式"><a href="#RLE组织格式" class="headerlink" title="RLE组织格式"></a>RLE组织格式</h3><pre><code>    |-- h36m
    `-- |-- annotations
        |   |-- Sample_trainmin_train_Human36M_protocol_2.json
        |   `-- Sample_64_test_Human36M_protocol_2.json
        `-- images
            |-- s_01_act_02_subact_01_ca_01
            |   |-- ...
            |-- s_01_act_02_subact_01_ca_02
            |   |-- ...
            `-- ... 
</code></pre>
<p>Human3.6是没有遮挡的数据的</p>
<p>18个关节点</p>
<p>Pixel-level 24 body part labels for each configuration</p>
<p>Time-of-flight range data 测距的数据</p>
<p>3D laser scans of the actors mesh数据</p>
<p><a target="_blank" rel="noopener" href="http://vision.imar.ro/human3.6m/description.php">http://vision.imar.ro/human3.6m/description.php</a></p>
<p>对于测距以及mesh的数据的描述</p>
<p>pose数据还包括relative 3D joint positions (R3DJP)和kinematic representation (KR)，KR用于描述物体的运动状态，例如位置、速度和加速度等。</p>
<img src="../images/POSE/image-20230721143257782.png" alt="image-20230721143257782" style="zoom:50%;" />

<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/h36m_annot.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/h36m_annot.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S1.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S1.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S5.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S5.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S6.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S6.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S7.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S7.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S8.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S8.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S9.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S9.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S11.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S11.tar</a></p>
<h1 id="学习RLE代码"><a href="#学习RLE代码" class="headerlink" title="学习RLE代码"></a>学习RLE代码</h1><h3 id="Train-on-MSCOCO"><a href="#Train-on-MSCOCO" class="headerlink" title="Train on MSCOCO"></a>Train on MSCOCO</h3><pre><code>./scripts/train.sh ./configs/256x192_res50_regress-flow.yaml train_rle_coco
</code></pre>
<p>train.sh里面的内容为：</p>
<pre><code>set -x
# 可以打开shell的调试模式，以便在shell执行时输出每个命令和其参数的执行结果。
CONFIG=$1 # 这将第一个命令行参数（$1）的值赋给名为CONFIG的变量。
EXPID=$&#123;2:-&quot;test_rle&quot;&#125; #  这将第二个命令行参数（$2）的值赋给名为EXPID的变量。如果第二个参数未提供，则						   #  EXPID的值将为&quot;test_rle&quot;。
PORT=$&#123;3:-23456&#125;
HOST=$(hostname -i)

python ./scripts/train.py --nThreads 16 \
    --launcher pytorch --rank 0 \
    --dist-url tcp://$&#123;HOST&#125;:$&#123;PORT&#125; \
    --exp-id $&#123;EXPID&#125; \
    --cfg $&#123;CONFIG&#125; --seed 123123
</code></pre>
<h3 id="写代码的技巧"><a href="#写代码的技巧" class="headerlink" title="写代码的技巧"></a>写代码的技巧</h3><h4 id="opt-snapshot"><a href="#opt-snapshot" class="headerlink" title="opt.snapshot"></a>opt.snapshot</h4><h4 id="‘pytorch’-‘slurm’-‘mpi’分布式平台"><a href="#‘pytorch’-‘slurm’-‘mpi’分布式平台" class="headerlink" title="‘pytorch’, ‘slurm’, ‘mpi’分布式平台"></a>‘pytorch’, ‘slurm’, ‘mpi’分布式平台</h4><h4 id="对于某些模块的特定初始化"><a href="#对于某些模块的特定初始化" class="headerlink" title="对于某些模块的特定初始化"></a>对于某些模块的特定初始化</h4><p>1.如果没有写在__init__里面写到类某个函数里面</p>
<p>如下面</p>
<pre><code>    def _initialize(self):
        for m in self.fcs:
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight, gain=0.01)
        for m in self.fc_layers:
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight, gain=0.01)
</code></pre>
<p>则要在类实列化后再使用model._initialize(),调用这个函数</p>
<h4 id="注册器类似于mmcv"><a href="#注册器类似于mmcv" class="headerlink" title="注册器类似于mmcv"></a>注册器类似于mmcv</h4><p>先弄一个Registry,属性有一个名字与一个字典，里面定义一个修饰器register_module，使用的时候如下</p>
<p>下面这段代码位于rlepose&#x2F;models&#x2F;<strong>init</strong>.py,在初始化的时候变导入啦</p>
<pre><code>@SPPE.register_module
class RegressFlow3D(nn.Module):
    pass
</code></pre>
<p>这样SPPE这个修饰器下面，属性字典里面就有一个key为RegressFlow3D,value为这个类对象的。</p>
<h4 id="损失类型"><a href="#损失类型" class="headerlink" title="损失类型"></a>损失类型</h4><h5 id="MSELoss"><a href="#MSELoss" class="headerlink" title="MSELoss"></a>MSELoss</h5><pre><code>@LOSS.register_module
class MSELoss(nn.Module):
    &#39;&#39;&#39; MSE Loss
    &#39;&#39;&#39;
    def __init__(self):
        super(MSELoss, self).__init__()
        self.criterion = nn.MSELoss()

    def forward(self, output, labels):
        pred_hm = output[&#39;heatmap&#39;]
        gt_hm = labels[&#39;target_hm&#39;]
        gt_hm_weight = labels[&#39;target_hm_weight&#39;]
        loss = 0.5 * self.criterion(pred_hm.mul(gt_hm_weight), gt_hm.mul(gt_hm_weight))

        return loss
</code></pre>
<h5 id="RLELoss"><a href="#RLELoss" class="headerlink" title="RLELoss"></a>RLELoss</h5><pre><code>class RLELoss(nn.Module):
    &#39;&#39;&#39; RLE Regression Loss
    &#39;&#39;&#39;

    def __init__(self, OUTPUT_3D=False, size_average=True):
        super(RLELoss, self).__init__()
        self.size_average = size_average
        self.amp = 1 / math.sqrt(2 * math.pi)

    def logQ(self, gt_uv, pred_jts, sigma):
        return torch.log(sigma / self.amp) + torch.abs(gt_uv - pred_jts) / (math.sqrt(2) * sigma + 1e-9)

    def forward(self, output, labels):
        nf_loss = output.nf_loss
        pred_jts = output.pred_jts
        sigma = output.sigma
        gt_uv = labels[&#39;target_uv&#39;].reshape(pred_jts.shape)
        gt_uv_weight = labels[&#39;target_uv_weight&#39;].reshape(pred_jts.shape)

        nf_loss = nf_loss * gt_uv_weight[:, :, :1]

        residual = True
        if residual:
            Q_logprob = self.logQ(gt_uv, pred_jts, sigma) * gt_uv_weight
            loss = nf_loss + Q_logprob

        if self.size_average and gt_uv_weight.sum() &gt; 0:
            return loss.sum() / len(loss)
        else:
            return loss.sum()
</code></pre>
<h5 id="RLELoss3D"><a href="#RLELoss3D" class="headerlink" title="RLELoss3D"></a>RLELoss3D</h5><pre><code>class RLELoss3D(nn.Module):
    &#39;&#39;&#39; RLE Regression Loss 3D
    &#39;&#39;&#39;

    def __init__(self, OUTPUT_3D=False, size_average=True):
        super(RLELoss3D, self).__init__()
        self.size_average = size_average
        self.amp = 1 / math.sqrt(2 * math.pi)

    def logQ(self, gt_uv, pred_jts, sigma):
        return torch.log(sigma / self.amp) + torch.abs(gt_uv - pred_jts) / (math.sqrt(2) * sigma + 1e-9)

    def forward(self, output, labels):
        nf_loss = output.nf_loss
        pred_jts = output.pred_jts
        sigma = output.sigma
        gt_uv = labels[&#39;target_uvd&#39;].reshape(pred_jts.shape)
        gt_uv_weight = labels[&#39;target_uvd_weight&#39;].reshape(pred_jts.shape)
        nf_loss = nf_loss * gt_uv_weight

        residual = True
        if residual:
            Q_logprob = self.logQ(gt_uv, pred_jts, sigma) * gt_uv_weight
            loss = nf_loss + Q_logprob

        if self.size_average and gt_uv_weight.sum() &gt; 0:
            return loss.sum() / len(loss)
        else:
            return loss.sum()
</code></pre>
<h4 id="SimpleTransform3D-object"><a href="#SimpleTransform3D-object" class="headerlink" title="SimpleTransform3D(object):"></a>SimpleTransform3D(object):</h4><pre><code>self.transformation = SimpleTransform3D(
self, 
scale_factor=self._scale_factor,  	# 0.3
color_factor=self._color_factor,	# 0.2
occlusion=self._occlusion,			# True
input_size=self._input_size,		# 256,256
output_size=self._output_size,		# 64,64
bbox_3d_shape=self.bbox_3d_shape,	# (2000, 2000, 2000)
rot=self._rot,						# 30
sigma=self._sigma,					# 2
train=self._train,					# true
add_dpg=self._dpg,					# false
loss_type=self._loss_type,			# &#39;coord&#39;
scale_mult=1)						
</code></pre>
<h4 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h4><pre><code>target = self.transformation(img, label)
img = target.pop(&#39;image&#39;)
bbox = target.pop(&#39;bbox&#39;)
return img, target, img_id, bbox
</code></pre>
<h4 id="class-H36m-data-Dataset"><a href="#class-H36m-data-Dataset" class="headerlink" title="class H36m(data.Dataset):"></a>class H36m(data.Dataset):</h4><pre><code>self._items, self._labels = self._lazy_load_json()
def _lazy_load_json(self):
     items, labels = self._load_jsons()
     
def _load_jsons(self):
    items = []
    labels = []	
    for ann_image, ann_annotations in zip(database[&#39;images&#39;], database[&#39;annotations&#39;]):     	#每一张图片
        items.append(abs_path)
        labels.append(&#123;
                &#39;bbox&#39;: (xmin, ymin, xmax, ymax),   # bbox_clip_xyxy
                &#39;img_id&#39;: image_id,
                &#39;img_path&#39;: abs_path,               # 图片绝对路径
                &#39;width&#39;: width,
                &#39;height&#39;: height,
                &#39;joint_img&#39;: joint_img,             # 一个相对的，相对中root关节点的坐标值，x,y不是相对的，z轴是相对的
                &#39;joint_vis&#39;: joint_vis,             # np.ones((self.num_joints, 3)) 18,3
                &#39;joint_cam&#39;: joint_cam,             # 18,3 world2cam
                &#39;root_cam&#39;: root_cam,               # root_cam
                &#39;tot_bone_len&#39;: tot_bone_len,       # 骨架的总长度
                &#39;f&#39;: f,
                &#39;c&#39;: c
            &#125;)
    return items, labels
</code></pre>

    </div>

    <div class="post-meta">
        <i>
        
            <span>2023-07-13</span>
            
                <span>该篇文章被 hong</span>
            
            
                <span>打上标签:
                    
                    
                        <a href='/tags/pose%E8%AE%BA%E6%96%87/'>
                            pose论文
                        </a>
                    
                </span>
             
             
        
        </i>
    </div>
    
        

     
</div>



                    
                    
                    <div class="footer">
    
        <span> 
             

            
                

            
        </span>
    
</div>
<!--这是指一条线往下的内容-->
<div class="footer-last">
    
            <span>花有重开日，人无再少年！</span>
            
                <span class="footer-last-span-right"><i>本站由<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>驱动｜使用<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>主题</i></span>
            
    
</div>


    
        
<link rel="stylesheet" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/a11y-dark.min.css">

        
<script src="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/js/highlight.min.js"></script>

        
<script src="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/js/highlightjs-line-numbers.js"></script>

    


<script>
    hljs.initHighlightingOnLoad();
    hljs.initLineNumbersOnLoad();
</script>
                </div>
            
    </body>
</html>