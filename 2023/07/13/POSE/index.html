<!DOCTYPE html>
<html lang="en">
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0,  viewport-fit=cover" name="viewport" />
    <meta name="description" content="POSE" />
    <meta name="hexo-theme-A4" content="v1.6.9" />
    <link rel="alternate icon" type="image/webp" href="/img/favicon.webp">
    <title>hwan | </title>

    
        
            
<link rel="stylesheet" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/reset.css">

            
<link rel="stylesheet" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/markdown.css">

            
<link rel="stylesheet" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/fonts.css">
 
            <!--注意：首页既不是post也不是page-->
            
        
    
    
<link rel="stylesheet" href="/css/ui.css">
 
    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.3.0"></head>
    
    <body>
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    
<div class="header">
    <div class="header-container">
        <img style="
        width: 56px;
        height: auto;" alt="^-^" cache-control="max-age=86400" class="header-img" src="/img/favicon.webp" width="10%"></img>
        <div class="header-content">
            <a class="logo" href="/">hwan</a> 
            <span class="description"></span> 
        </div>
        
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">首页</a></li>
            
        
            
                <li><a href="/list/">文章</a></li>
            
        
            
                <li><a href="/about/">关于</a></li>
            
        
            
                <li><a href="/tags/">标签</a></li>
            
        
            
                <li><a href="/categories/">分类</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--说明是文章post页面-->
                    
                        <div class="post-main">

    
        <div class="post-main-title">
            POSE
        </div>
      
    

    <div class="post-md">
        
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#RLE"><span class="post-toc-text">RLE</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E4%B8%8E%E5%A7%BF%E6%80%81%E7%9B%B8%E5%85%B3%E7%9A%84%E8%AE%BA%E6%96%87%E4%B8%BB%E8%A6%81%E7%9C%8B%E6%95%B0%E6%8D%AE%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84"><span class="post-toc-text">与姿态相关的论文主要看数据组织结构</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#DAS"><span class="post-toc-text">DAS</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#voxel-pose"><span class="post-toc-text">voxel_pose</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#PCT"><span class="post-toc-text">PCT</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#GFPose"><span class="post-toc-text">GFPose</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%A7%BF%E6%80%81%E7%9B%B8%E5%85%B3%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="post-toc-text">姿态相关的数据</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#CrowdPose"><span class="post-toc-text">CrowdPose</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#OCHuman"><span class="post-toc-text">OCHuman</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#SyncOCC"><span class="post-toc-text">SyncOCC</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MPII"><span class="post-toc-text">MPII</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#CMU-Panoptic"><span class="post-toc-text">CMU Panoptic</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"><span class="post-toc-text">使用方法</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#COCO-keypoint%E6%95%B0%E6%8D%AE"><span class="post-toc-text">COCO keypoint数据</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MuPoTS"><span class="post-toc-text">MuPoTS</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MuCo"><span class="post-toc-text">MuCo</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Human-3-6%E4%BD%BF%E7%94%A8"><span class="post-toc-text">Human 3.6使用</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#POSENET%E7%BB%84%E7%BB%87%E6%A0%BC%E5%BC%8F"><span class="post-toc-text">POSENET组织格式</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#RLE%E7%BB%84%E7%BB%87%E6%A0%BC%E5%BC%8F"><span class="post-toc-text">RLE组织格式</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8RLE-loss"><span class="post-toc-text">如何使用RLE loss</span></a></li></ol>
        
        <h1 id="RLE"><a href="#RLE" class="headerlink" title="RLE"></a>RLE</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/625023463">https://zhuanlan.zhihu.com/p/625023463</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/440567782">https://zhuanlan.zhihu.com/p/440567782</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Jeff-sjtu/res-loglikelihood-regression">https://github.com/Jeff-sjtu/res-loglikelihood-regression</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV18E411w7Jh/?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV18E411w7Jh/?spm_id_from=333.999.0.0</a> 讲flow的视频</p>
<p>GAN训练：模式崩溃和后置崩溃挑战</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/165577850">https://zhuanlan.zhihu.com/p/165577850</a> flow的文章</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59615785">https://zhuanlan.zhihu.com/p/59615785</a> 讲flow的文章</p>
<pre><code>20个采样点 10个实列
all number of params: 43108693
number of backbone params: 33841352
</code></pre>
<pre><code>20个采样点 5个实列
all number of params: 43105908
number of backbone params: 33841352
</code></pre>
<pre><code>10个采样点 5个实列
all number of params: 42365748
number of backbone params: 33841352
</code></pre>
<p>19416917</p>
<p>尺寸不变</p>
<pre><code>kernel_size=3, padding=1, stride=1 
kernel_size=5, padding=2, stride=1
kernel_size=7, padding=3, stride=1
</code></pre>
<h1 id="与姿态相关的论文主要看数据组织结构"><a href="#与姿态相关的论文主要看数据组织结构" class="headerlink" title="与姿态相关的论文主要看数据组织结构"></a>与姿态相关的论文主要看数据组织结构</h1><h2 id="DAS"><a href="#DAS" class="headerlink" title="DAS"></a>DAS</h2><pre><code>$&#123;ROOT&#125;
|-- data
|   |-- panoptic
|   |   |-- 160226_haggling1
|   |   |   |-- hdImgs
|   |   |   |   |-- 00_16
|   |   |   |   |-- 00_30
|   |   |-- 160422_haggling1
|   |   |-- 160226_mafia1
|   |   |-- 160422_mafia2
|   |   |-- 160226_ultimatum1
|   |   |-- 160422_ultimatum1
|   |   |-- 160906_pizza1
|   |   |-- annotations
|   |   |   |-- train.json
|   |   |   |-- haggling.json
|   |   |   |-- mafia.json
|   |   |   |-- ultimatum.json
|   |   |   |-- pizza.json
|   |-- coco
|   |   |-- train2017
|   |   |-- annotations
|   |   |   |-- person_keypoints_train2017.json
|   |-- muco
|   |   |-- unaugmented_set
|   |   |-- augmented_set
|   |   |-- annotations
|   |   |   |-- train_all_interv1.json
|   |-- mupots
|   |   |-- TS1
|   |   |   |-- img_000000.jpg
|   |   |   |-- ...
|   |   |-- ...
|   |   |-- TS20
|   |   |-- annotations
|   |   |   |-- MuPoTS-3D.json
</code></pre>
<h2 id="voxel-pose"><a href="#voxel-pose" class="headerlink" title="voxel_pose"></a>voxel_pose</h2><pre><code>$&#123;POSE_ROOT&#125;
|-- models
|   |-- pose_resnet50_panoptic.pth.tar
|-- data
    |-- panoptic-toolbox
        |-- data
            |-- 16060224_haggling1
            |   |-- hdImgs
            |   |-- hdvideos
            |   |-- hdPose3d_stage1_coco19
            |   |-- calibration_160224_haggling1.json
            |-- 160226_haggling1  
            |-- ...
</code></pre>
<h2 id="PCT"><a href="#PCT" class="headerlink" title="PCT"></a>PCT</h2><pre><code>$&#123;POSE_ROOT&#125;
|-- data
`-- |-- coco
    `-- |-- annotations
        |   |-- person_keypoints_train2017.json
        |   `-- person_keypoints_val2017.json
        |-- person_detection_results
        |   |-- COCO_val2017_detections_AP_H_56_person.json
        |   |-- COCO_test-dev2017_detections_AP_H_609_person.json
        `-- images
            |-- train2017
            |   |-- 000000000009.jpg
            |   |-- 000000000025.jpg
            |   |-- 000000000030.jpg
            |   |-- ... 
            `-- val2017
                |-- 000000000139.jpg
                |-- 000000000285.jpg
                |-- 000000000632.jpg
                |-- ... 
</code></pre>
<h2 id="GFPose"><a href="#GFPose" class="headerlink" title="GFPose"></a>GFPose</h2><pre><code>$&#123;POSE_ROOT&#125;
|-- configs
|-- lib
|-- run
|-- checkpoint
    |-- u3d
        |-- best_model.pth
|-- data
    |-- h36m
        |-- h36m_train.pkl
        |-- h36m_test.pkl
        |-- h36m_sh_dt_ft.pkl
</code></pre>
<h1 id="姿态相关的数据"><a href="#姿态相关的数据" class="headerlink" title="姿态相关的数据"></a>姿态相关的数据</h1><h2 id="CrowdPose"><a href="#CrowdPose" class="headerlink" title="CrowdPose"></a>CrowdPose</h2><h2 id="OCHuman"><a href="#OCHuman" class="headerlink" title="OCHuman"></a>OCHuman</h2><h2 id="SyncOCC"><a href="#SyncOCC" class="headerlink" title="SyncOCC"></a>SyncOCC</h2><p>合成的数据</p>
<h2 id="MPII"><a href="#MPII" class="headerlink" title="MPII"></a>MPII</h2><p>The dataset includes around <strong>25K images</strong> containing over <strong>40K people</strong> with annotated body joints；</p>
<p><strong>410 human activities</strong> and each image is provided with an activity label；</p>
<p>POSENET也有下载链接，组织为</p>
<pre><code>|   |-- MPII
|   |   |-- images
|   |   |-- annotations
</code></pre>
<p>官网也有</p>
<p><a target="_blank" rel="noopener" href="http://human-pose.mpi-inf.mpg.de/#download">http://human-pose.mpi-inf.mpg.de/#download</a></p>
<h2 id="CMU-Panoptic"><a href="#CMU-Panoptic" class="headerlink" title="CMU Panoptic"></a>CMU Panoptic</h2><p><a target="_blank" rel="noopener" href="http://domedb.perception.cs.cmu.edu/">http://domedb.perception.cs.cmu.edu/</a> 数据主页</p>
<p><a target="_blank" rel="noopener" href="https://github.com/CMU-Perceptual-Computing-Lab/panoptic-toolbox">https://github.com/CMU-Perceptual-Computing-Lab/panoptic-toolbox</a></p>
<p>31个 多视角HD video（高清视频）通常指 1080p（1920x1080 像素）或更高分辨率的视频。</p>
<h6 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h6><p>下载这个PanopticStudio Toolbox，然后</p>
<pre><code>./scripts/getData.sh 171204_pose1_sample 举列子
./scripts/getData.sh 171204_pose1

./scripts/getData.sh (sequenceName) (VGA_Video_Number) (HD_Video_Number)
列如./scripts/getData.sh 171204_pose1_sample 240 10 
240 vga videos and 10 videos.

可选的序列名称
https://docs.google.com/spreadsheets/d/1eoe74dHRtoMVVFLKCTJkAtF8zqxAnoo2Nt15CYYvHEE/edit#gid=1333444170

./scripts/getDB_panopticHD_ver1_2.sh
下载1.2数据版本所有数据
上述命令默认是不下载视频数据的，就要像上面一样指定视频个数

假如说现在下载好了视频，需要将视频变成每一帧每一帧的，然后将一视频的标签也变成一帧一帧图片对应的pose;注需要ffmpeg
运行这个命令有
./scripts/extractAll.sh 171204_pose1_sample
171204_pose1_sample/hdImgs/00_00/00_00_00000000.jpg
171204_pose1_sample/hdPose3d_stage1_coco19/body3DScene_00000000.json

在这个工具里面有一些可视化的代码，以及从3D重投影到2D的方法
还有一些kinect数据点云的

注：https://github.com/wangzt-halo/das在DAS这个项目有一个代码可以将原始标签转化
</code></pre>
<p>480 views VGA video（标准视频）是指分辨率为 640x480 像素的视频。</p>
<ul>
<li>171204_pose1_sample&#x2F;hdVideos&#x2F;hd_00_XX.mp4  #synchronized HD video files (31 views)</li>
<li>171204_pose1_sample&#x2F;vgaVideos&#x2F;KINECTNODE%d&#x2F;vga_XX_XX.mp4 #synchrponized VGA video files (480 views)</li>
<li>171204_pose1_sample&#x2F;calibration_171204_pose1_sample.json #calibration files</li>
<li>171204_pose1_sample&#x2F;hdPose3d_stage1_coco19.tar #3D Body Keypoint Data (coco19 keypoint definition)</li>
<li>171204_pose1_sample&#x2F;hdFace3d.tar #3D Face Keypoint Data</li>
<li>171204_pose1_sample&#x2F;hdHand3d.tar #3D Hand Keypoint Data</li>
</ul>
<h2 id="COCO-keypoint数据"><a href="#COCO-keypoint数据" class="headerlink" title="COCO keypoint数据"></a>COCO keypoint数据</h2><p>150K训练5K验证30K测试</p>
<img src="../images/POSE/image-20230721142637523.png" alt="image-20230721142637523" style="zoom:80%;" />

<img src="../images/POSE/image-20230721142828338.png" alt="image-20230721142828338" style="zoom:50%;" />

<img src="../images/POSE/image-20230721142920961.png" alt="image-20230721142920961" style="zoom:80%;" />



<h2 id="MuPoTS"><a href="#MuPoTS" class="headerlink" title="MuPoTS"></a>MuPoTS</h2><p>POSENET组织格式</p>
<p>POSENET也有下载链接</p>
<pre><code>|   |-- MuPoTS
|   |   |-- bbox_root
|   |   |   |-- bbox_mupots_output.json
|   |   |-- data
|   |   |   |-- MultiPersonTestSet
|   |   |   |-- MuPoTS-3D.json
</code></pre>
<h2 id="MuCo"><a href="#MuCo" class="headerlink" title="MuCo"></a>MuCo</h2><p>POSENET组织格式</p>
<p>POSENET也有下载链接</p>
<pre><code>|   |-- MuCo
|   |   |-- data
|   |   |   |-- augmented_set
|   |   |   |-- unaugmented_set
|   |   |   |-- MuCo-3DHP.json
</code></pre>
<h2 id="Human-3-6使用"><a href="#Human-3-6使用" class="headerlink" title="Human 3.6使用"></a>Human 3.6使用</h2><p>原始数据下载</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42951560/article/details/126380971">https://blog.csdn.net/qq_42951560/article/details/126380971</a></p>
<h3 id="POSENET组织格式"><a href="#POSENET组织格式" class="headerlink" title="POSENET组织格式"></a>POSENET组织格式</h3><p>POSENET也有下载链接</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mks0601/3DMPPE_POSENET_RELEASE">https://github.com/mks0601/3DMPPE_POSENET_RELEASE</a></p>
<pre><code>|   |-- Human36M
|   |   |-- bbox_root
|   |   |   |-- bbox_root_human36m_output.json
|   |   |-- images
|   |   |-- annotations
</code></pre>
<h3 id="RLE组织格式"><a href="#RLE组织格式" class="headerlink" title="RLE组织格式"></a>RLE组织格式</h3><pre><code>    |-- h36m
    `-- |-- annotations
        |   |-- Sample_trainmin_train_Human36M_protocol_2.json
        |   `-- Sample_64_test_Human36M_protocol_2.json
        `-- images
            |-- s_01_act_02_subact_01_ca_01
            |   |-- ...
            |-- s_01_act_02_subact_01_ca_02
            |   |-- ...
            `-- ... 
</code></pre>
<p>Human3.6是没有遮挡的数据的</p>
<p>Pixel-level 24 body part labels for each configuration</p>
<p>Time-of-flight range data 测距的数据</p>
<p>3D laser scans of the actors mesh数据</p>
<p><a target="_blank" rel="noopener" href="http://vision.imar.ro/human3.6m/description.php">http://vision.imar.ro/human3.6m/description.php</a></p>
<p>对于测距以及mesh的数据的描述</p>
<p>pose数据还包括relative 3D joint positions (R3DJP)和kinematic representation (KR)，KR用于描述物体的运动状态，例如位置、速度和加速度等。</p>
<img src="../images/POSE/image-20230721143257782.png" alt="image-20230721143257782" style="zoom:50%;" />

<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/h36m_annot.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/h36m_annot.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S1.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S1.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S5.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S5.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S6.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S6.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S7.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S7.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S8.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S8.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S9.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S9.tar</a></p>
<p><a target="_blank" rel="noopener" href="http://visiondata.cis.upenn.edu/volumetric/h36m/S11.tar">http://visiondata.cis.upenn.edu/volumetric/h36m/S11.tar</a></p>
<h1 id="如何使用RLE-loss"><a href="#如何使用RLE-loss" class="headerlink" title="如何使用RLE loss"></a>如何使用RLE loss</h1>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2023-07-13</span>
            
                <span>该篇文章被 hong</span>
            
            
                <span>打上标签:
                    
                    
                        <a href='/tags/pose%E8%AE%BA%E6%96%87/'>
                            pose论文
                        </a>
                    
                </span>
             
             
        
        </i>
    </div>
    
        

     
</div>



                    
                    
                    <div class="footer">
    
        <span> 
             

            
                

            
        </span>
    
</div>
<!--这是指一条线往下的内容-->
<div class="footer-last">
    
            <span>花有重开日，人无再少年！</span>
            
                <span class="footer-last-span-right"><i>本站由<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>驱动｜使用<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>主题</i></span>
            
    
</div>


    
        
<link rel="stylesheet" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/a11y-dark.min.css">

        
<script src="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/js/highlight.min.js"></script>

        
<script src="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/js/highlightjs-line-numbers.js"></script>

    


<script>
    hljs.initHighlightingOnLoad();
    hljs.initLineNumbersOnLoad();
</script>
                </div>
            
    </body>
</html>