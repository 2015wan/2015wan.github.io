<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>搭建博客记录</title>
    <url>/2023/06/26/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<ol>
<li><a href="https://blog.csdn.net/yaorongke/article/details/119089190">https://blog.csdn.net/yaorongke/article/details/119089190</a> 龙哥的链接</li>
<li>hexo主题相关的<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></li>
<li>我博客使用的主题<a href="https://github.com/HiNinoJay/hexo-theme-A4">https://github.com/HiNinoJay/hexo-theme-A4</a></li>
<li>typora添加图片<a href="https://blog.51cto.com/u_15854687/5811585">https://blog.51cto.com/u_15854687/5811585</a><br><a href="https://blog.csdn.net/Qxiaofei_/article/details/124629908">https://blog.csdn.net/Qxiaofei_/article/details/124629908</a></li>
<li>typora安装url</li>
</ol>
]]></content>
      <tags>
        <tag>杂</tag>
      </tags>
  </entry>
  <entry>
    <title>ovd</title>
    <url>/2023/06/27/ovd/</url>
    <content><![CDATA[<h6 id="COCO数据集"><a href="#COCO数据集" class="headerlink" title="COCO数据集"></a>COCO数据集</h6><p>Base类48个，Novel17个，一共65个。</p>
<h6 id="多模态相关工作"><a href="#多模态相关工作" class="headerlink" title="多模态相关工作"></a>多模态相关工作</h6><p>CLIP、ALIGN、R2D2</p>
<h6 id="OVR-CNN"><a href="#OVR-CNN" class="headerlink" title="OVR-CNN"></a>OVR-CNN</h6><p>无类别区域检测器与无标注数据的跨模态模型</p>
<p><img src="/../images/ovd/image-20230627105546152.png" alt="image-20230627105546152"></p>
<p><img src="/../images/ovd/image-20230627110708030.png" alt="image-20230627110708030"></p>
<p>待看后两篇 <a href="https://mp.weixin.qq.com/s/f7hlh32TGPwktRhc64yejw">https://mp.weixin.qq.com/s/f7hlh32TGPwktRhc64yejw</a> </p>
]]></content>
      <tags>
        <tag>detect</tag>
      </tags>
  </entry>
  <entry>
    <title>hw</title>
    <url>/2023/06/27/hw/</url>
    <content><![CDATA[<h6 id="杂"><a href="#杂" class="headerlink" title="杂"></a>杂</h6><pre><code>
tree = struct(&#39;value&#39;, &#39;null&#39;, &#39;left&#39;, &#39;null&#39;, &#39;right&#39;, &#39;null&#39;);
相当于字典
值的索引是tree.value,用点的方式
#
length(attrib) attrib shape为150，5 返回150
索引是 attrib(:,1) 圆括号，从1开始
# 
bool数组对应的logical数组，可以用sum函数
#
</code></pre>
<h6 id="sortrows函数的使用："><a href="#sortrows函数的使用：" class="headerlink" title="sortrows函数的使用："></a>sortrows函数的使用：</h6><p>函数返回一个按照指定列排序后的矩阵或表格。如果两行在排序列中具有相同的值，则按照后续列进行排序。如果两行在所有列中都具有相同的值，则它们的顺序在结果中未定义。</p>
<p>例如，以下代码将一个3x3的矩阵按第二列进行排序：</p>
<p>A &#x3D; [4 3 9; 2 1 8; 7 6 5];<br>B &#x3D; sortrows(A, 2);</p>
<p>B &#x3D;<br>2 1 8<br>7 6 5<br>4 3 9</p>
<h6 id="cell-array"><a href="#cell-array" class="headerlink" title="cell array"></a>cell array</h6><pre><code>attri&#123;1,1&#125;=sortrows(attrib,1);
attri&#123;1,2&#125;=sortrows(attrib,2);
attri&#123;1,3&#125;=sortrows(attrib,3);
attri&#123;1,4&#125;=sortrows(attrib,4);
</code></pre>
<p>在Matlab中，<code>attri</code>的数据类型取决于 <code>sortrows</code> 函数的输出。根据代码中的赋值语句，我们可以猜测 <code>attri</code> 是一个单元格数组（cell array）。</p>
<p>单元格数组是Matlab中的一种数据类型，可以存储不同类型的数据，包括矩阵、向量、字符数组等等。它们可以通过花括号 <code>&#123;&#125;</code> 引用其中的元素，例如 <code>attri&#123;1,1&#125;</code> 就是单元格数组 <code>attri</code> 中第1行第1列元素的值。</p>
<p>在这个赋值语句中，<code>sortrows</code> 函数的输出是一个按第1列排序后的矩阵，然后将其赋值给 <code>attri&#123;1,1&#125;</code> 这个单元格数组的第1行第1列元素。因此，<code>attri</code> 的类型是单元格数组，而 <code>attri&#123;1,1&#125;</code> 的类型是矩阵。</p>
<h5 id="复杂语句"><a href="#复杂语句" class="headerlink" title="复杂语句"></a>复杂语句</h5><p>1:3 &#x3D; 1 2 3 开始与结束都包括</p>
<h6 id="循环语句"><a href="#循环语句" class="headerlink" title="循环语句"></a>循环语句</h6><pre><code class="matlab">for i = start:end
    ~
end
</code></pre>
<h6 id="逻辑判断符"><a href="#逻辑判断符" class="headerlink" title="逻辑判断符"></a>逻辑判断符</h6><p>不等于~&#x3D; </p>
]]></content>
      <tags>
        <tag>杂</tag>
      </tags>
  </entry>
  <entry>
    <title>生成模型</title>
    <url>/2023/06/29/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="Oh, these decrypted content cannot be verified, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="5057b9112820d7395cbe1c7f38c24e6181012e2ac82551ee34fb6fe04422641f">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <tags>
        <tag>生成模型</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/06/29/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/</url>
    <content><![CDATA[<h1 id="梯度投影法原理"><a href="#梯度投影法原理" class="headerlink" title="梯度投影法原理"></a><strong>梯度投影法原理</strong></h1><h2 id="一、解决问题"><a href="#一、解决问题" class="headerlink" title="一、解决问题"></a>一、解决问题</h2><p>​		在无约束优化问题中，我们一般使用梯度下降法便可以找到凸优化问题的最优解，但是如果有约束呢，这时候梯度投影法给出自己的做法，便是通过约束条件来重新计算可行方向，以及在这个可行方向下降多少步可以。</p>
<p>​		考虑问题：<br>$$<br>\begin{array}{ll}<br>\min &amp; f(\boldsymbol{x}) \<br>\text { s.t. } &amp; \boldsymbol{A} \boldsymbol{x} \geqslant \boldsymbol{b}, \<br>&amp; \boldsymbol{E} \boldsymbol{x}&#x3D;\boldsymbol{e},<br>\end{array}<br>$$<br>其中$$f(\boldsymbol{x})$$是可微函数 ,A 为 m × n 矩阵 ，E 为 l × n 矩阵。梯度投影法的基本思想仍然是从可行点出发 ，沿可行方向进行搜索 ．当迭代出发点在可行域内部时 ，沿负梯度方向搜索 ．当迭代出发点在某些约束的边界上时 ，将该点处的负梯度投影到 M 的零空间 ，M 是以起作用约束或部分起作用约束的梯度为行构造成的矩阵 。</p>
<p>​		现在抛开梯度投影法是如何投影这件事，了解一下什么叫做有约束条件下的可行方向，给出定理即， <strong>d</strong> 为$$\hat{\boldsymbol{x}}$$</p>
<p>处的可行方向是如下定义的，首先假设$$\hat{\boldsymbol{x}}$$是上述优化问题的可行解，那么对于不等式约束有$$<br>\boldsymbol{A}_1 \hat{\boldsymbol{x}}&#x3D;\boldsymbol{b}_1, \boldsymbol{A}_2 \hat{\boldsymbol{x}}&gt;\boldsymbol{b}_2<br>$$，其中A &#x3D; [$$A_1$$;$$A_2$$],b&#x3D;[$$b_1$$;$$b_2$$],非零向量d为$$\hat{\boldsymbol{x}}$$处的可行方向的充要条件是$$<br>A_1 d \geqslant \mathbf{0}, \boldsymbol{E d}&#x3D;\mathbf{0}<br>$$。</p>
<p>​		现在假设我们有一个可行方向，那应该按这个方向移动多少步呢？假设$$\boldsymbol{x}^{(k)}$$位置，$$\boldsymbol{x}^{(k+1)}$$是接下来通过可行方向移动$$\lambda$$长距离得到的点，其中$$\lambda$$是解下面优化便可以得到：<br>$$<br>\begin{array}{ll}<br>\min &amp; f\left(\boldsymbol{x}^{(k)}+\lambda \boldsymbol{d}^{(k)}\right) \<br>\text { s.t. } &amp; 0 \leqslant \lambda \leqslant \lambda_{\max },<br>\end{array}<br>$$<br>​		其中，$$\lambda _ {max}$$是由下式得到的:<br>$$<br>\lambda _{\max}&#x3D;\begin{cases}<br>    \min \left{ \frac{\hat{b}_i}{\hat{d}_i}\mid \hat{d}_i&lt;0 \right} ,&amp;		\boldsymbol{\hat{d}}\ngeq 0,\<br>    \infty ,&amp;		\boldsymbol{\hat{d}}\ge 0\<br>\end{cases}<br>$$<br>​		重新回到梯度投影法，首先是梯度投影法是如何修改负梯度方向为带约束对应下的可行方向，设x是上面优化问题的可行解，在点x处，有$$\boldsymbol{A}_1 \hat{\boldsymbol{x}}&#x3D;\boldsymbol{b}_1, \boldsymbol{A}_2 \hat{\boldsymbol{x}}&gt;\boldsymbol{b}_2$$,其中$$A &#x3D; [$$A_1$$;$$A_2$$],b&#x3D;[$$b_1$$;$$b_2],这时候把令不等式约束为等号的条件即$$A_1$$拿出来，构造新的矩阵M&#x3D;[$$A_1$$;E],构造投影矩阵$$\boldsymbol{P}&#x3D;\boldsymbol{I}-\boldsymbol{M}^{\text{T}}\left( \boldsymbol{MM}^{\text{T}} \right) ^{-1}\boldsymbol{M,P}\Delta f\left( \boldsymbol{x} \right) \ne 0$$</p>
<p>令$$\boldsymbol{d}&#x3D;-\boldsymbol{P} \Delta f(\boldsymbol{x})$$,则d是下降可行方向！那么知道梯度投影法是如何得到下降可行方向，那么是如何用的呢？梯度下降法计算步骤如下:</p>
<p>1.给定初始可行点$$x^{(1)}$$,置k&#x3D;1。</p>
<p>2.在点$$x^{(k)}$$处，将A和b分解成：<br>$$<br>\begin{equation}<br>\left[\begin{array}{l}<br>\boldsymbol{A}_1 \<br>\boldsymbol{A}_2<br>\end{array}\right],\left[\begin{array}{l}<br>\boldsymbol{b}_1 \<br>\boldsymbol{b}_2<br>\end{array}\right],<br>\end{equation}<br>$$<br>使得$$\boldsymbol{A}_1 \boldsymbol{x}^{(k)}&#x3D;\boldsymbol{b}_1, \boldsymbol{A}_2 \boldsymbol{x}^{(k)}&gt;\boldsymbol{b}_2$$</p>
<p>3.令:<br>$$<br>\begin{equation}<br>\boldsymbol{M}&#x3D;\left[\begin{array}{c}<br>\boldsymbol{A}_1 \<br>\boldsymbol{E}<br>\end{array}\right]<br>\end{equation}<br>$$<br>如果M是空的，则令 P&#x3D;I（单位矩阵），当P是单位矩阵的时候就是相当于梯度下降，否则令$$\boldsymbol{P}&#x3D;\boldsymbol{I}-\boldsymbol{M}^{\text{T}}\left( \boldsymbol{MM}^{\text{T}} \right) ^{-1}\boldsymbol{M,}$$</p>
<p>4.令$$\boldsymbol{d}^{(k)}&#x3D;-\boldsymbol{P} \Delta f\left(\boldsymbol{x}^{(k)}\right)$$, 若$$\boldsymbol{d}^{(k)} \neq \mathbf{0}$$,则转步骤6；若$$\boldsymbol{d}^{(k)}&#x3D;\mathbf{0}$$，则进行步骤5</p>
<p>5.若M是空的，则停止计算，得到$$\boldsymbol{x}^{(k)}$$;否则，令<br>$$<br>\begin{equation}<br>\boldsymbol{W}&#x3D;\left(\boldsymbol{M} \boldsymbol{M}^{\mathrm{T}}\right)^{-1} \boldsymbol{M} \Delta f\left(\boldsymbol{x}^{(k)}\right)&#x3D;\left[\begin{array}{l}<br>\boldsymbol{u} \<br>\boldsymbol{v}<br>\end{array}\right]<br>\end{equation}<br>$$<br>如果$$u \geqslant 0$$,则停止计算，$$x^{(k)}$$为K-T点，如果 u 包含负分量 ，则选择一个负分量 ，比如$$u_j$$,修正$$A_1$$,去掉$$A_1$$中对应$$u_j$$的行,返回步骤3</p>
<p>6.解下列问题，求步长$$\lambda_k$$:<br>$$<br>\begin{array}{ll}<br>\min &amp; f\left(\boldsymbol{x}^{(k)}+\lambda \boldsymbol{d}^{(k)}\right) \<br>\text { s.t. } &amp; 0 \leqslant \lambda \leqslant \lambda_{\max },<br>\end{array}<br>$$<br>$$\lambda_{\max }$$算完，得到解$$\lambda_k$$,令<br>$$<br>\begin{equation}<br>\boldsymbol{x}^{(k+1)}&#x3D;\boldsymbol{x}^{(k)}+\lambda_z \boldsymbol{d}^{(k)}<br>\end{equation}<br>$$<br>接着k&#x3D;k+1,返回步骤2。</p>
<h2 id="二、代码简单实现"><a href="#二、代码简单实现" class="headerlink" title="二、代码简单实现"></a>二、代码简单实现</h2><p>使用matlab实现精度参数ε对优化结果的影响初始点位置对优化结果的影响陷入局部最优解；</p>
<p>约束条件为：<br>$$<br>\begin{equation}<br>A&#x3D;\left(\begin{array}{cc}<br>-1 &amp; -1 \<br>-1 &amp; -5 \<br>1 &amp; 0 \<br>0 &amp; 1<br>\end{array}\right), B&#x3D;\left(\begin{array}{c}<br>-2 \<br>-5 \<br>0 \<br>0<br>\end{array}\right)<br>\end{equation}<br>$$<br><img src="D:/person_blog/blog/source/images/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/image-20230629165937006.png" alt="image-20230629165937006"></p>
<p><img src="D:/person_blog/blog/source/images/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/image-20230629165949456.png" alt="image-20230629165949456"></p>
<h2 id="三、代码结果"><a href="#三、代码结果" class="headerlink" title="三、代码结果"></a>三、代码结果</h2><h3 id="1-初始点的影响"><a href="#1-初始点的影响" class="headerlink" title="1.初始点的影响"></a>1.初始点的影响</h3><p>目标函数 $$f(x)&#x3D;\left(x_1^2+x_2-11\right)^2+\left(x_1+x_2^2-7\right)^2$$,初始点(0.5, 0.8),讨论参数$$\mathcal{E}$$越大，搜索的速度越快，迭代次数越少；越小，搜索的粒度越细，越可能找到最优解。参数$$\mathcal{E}$$&#x3D;1e−6。</p>
<p>初始点的位置选取是获得最优解的关键影响最优解的值和收敛速度。</p>
<p><img src="D:/person_blog/blog/source/images/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/image-20230629170654684.png" alt="image-20230629170654684"></p>
<p><img src="D:/person_blog/blog/source/images/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/image-20230629170820125.png" alt="image-20230629170820125"></p>
<h3 id="2-陷入局部优化"><a href="#2-陷入局部优化" class="headerlink" title="2.陷入局部优化"></a>2.陷入局部优化</h3><p>目标函数$$f(x)&#x3D;2 x_1^2-1.05 x_1^4+\frac{1}{6} x_1^6+x_1 x_2+x_2^4$$,$$\varepsilon&#x3D;1 e-6$$,初始点的位置选取是获得最优解的关键,陷入局部最优解;</p>
<p><img src="D:/person_blog/blog/source/images/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/image-20230629171152819.png" alt="image-20230629171152819"></p>
<p><img src="D:/person_blog/blog/source/images/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/image-20230629171228001.png" alt="image-20230629171228001"></p>
<h3 id="3-初始点的位置影响优化结果"><a href="#3-初始点的位置影响优化结果" class="headerlink" title="3.初始点的位置影响优化结果"></a>3.初始点的位置影响优化结果</h3><p>目标函数$$f(x)&#x3D;-20 e^{-0.2 \sqrt{0.5\left(x_1^2+x_2^2\right)}}-e^{0.5\left(\cos \left(2 \pi x_2\right)\right)}+20+e$$,,$$\varepsilon&#x3D;1 e-6$$,</p>
<p><img src="D:/person_blog/blog/source/images/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/image-20230629171417845.png" alt="image-20230629171417845"></p>
<p><img src="D:/person_blog/blog/source/images/%E6%A2%AF%E5%BA%A6%E6%8A%95%E5%BD%B1%E6%B3%95/image-20230629171453237.png" alt="image-20230629171453237"></p>
<h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>优点：直接沿负梯度下降的方式可能导致非可行点，保持迭代点的可行性获得最优解，可用于凸优化、非凸优化问题，对约束条件没有太多限制</p>
<p>缺点：基于梯度，无法解决非光滑问题，算法结果与运行速度受初始点位置影响较大，仍然可能陷入局部最优解，无法避免发生振荡，无法解决高度非凸优化问题</p>
]]></content>
  </entry>
  <entry>
    <title>三维重建</title>
    <url>/2023/07/05/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/</url>
    <content><![CDATA[<h5 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h5><h6 id="多视图三维重建的传统流程"><a href="#多视图三维重建的传统流程" class="headerlink" title="多视图三维重建的传统流程"></a>多视图三维重建的传统流程</h6><ul>
<li><p>多视图三维重建的传统流程：</p>
</li>
<li><p>图像特征匹配，SfM求解相机位姿，MVS稠密重建</p>
<p>相机位姿（Camera Pose）是指相机在三维空间中的位置和朝向,旋转矩阵和一个平移向量来描述相机位姿为了实现MVS稠密重建，</p>
<p>MVS 稠密重建通常包括以下步骤：</p>
<ol>
<li>xxxxxxxxxx if torch.cuda.is_available():    model.cuda()python</li>
<li>基础矩阵和本质矩阵估计。使用特征点匹配，可以估计相邻图像之间的基础矩阵或本质矩阵，这些矩阵描述了相机之间的几何关系，包括旋转和平移。</li>
<li>稠密点云重建。根据相邻图像之间的几何关系，可以将每个像素点从图像坐标系转换到世界坐标系。将这些点云数据结合起来，可以得到一个稠密的点云模型。</li>
<li>点云表面重建。稠密点云中包含大量的噪声和无用点，需要进行过滤和表面重建，得到一个光滑的表面模型。</li>
</ol>
<p>需要进行以下步骤：</p>
</li>
</ul>
<ol>
<li>相机位姿估计：利用SfM技术估计每个视角的相机位姿。</li>
<li>立体匹配：对于每个像素点，利用多个视角的图像进行立体匹配，估计该像素点在三维空间中的位置。</li>
<li>三维重建：将所有像素点的三维位置整合起来，重建出整个物体的三维几何形状。</li>
</ol>
<ul>
<li>缺点：重建流程<a href="https://www.zhihu.com/search?q=%E9%B2%81%E6%A3%92%E6%80%A7&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2648027035%7D">鲁棒性</a>差，不可导：无反馈机制</li>
</ul>
<h6 id="基于表示学习的图像特征匹配："><a href="#基于表示学习的图像特征匹配：" class="headerlink" title="基于表示学习的图像特征匹配："></a>基于表示学习的图像特征匹配：</h6><ul>
<li>​	SuperPoint，SuperGlue、ORB</li>
</ul>
<p>SuperPoint具有更快的速度和更好的鲁棒性。SuperPoint使用卷积神经网络来学习特征表示，其中包括特征点的位置、尺度和方向，以及对应的描述子。</p>
<p>SuperGlue是一种基于深度学习的图像特征匹配算法，它可以通过对两个图像中提取的特征进行匹配，找到它们之间的对应关系和相对位姿。</p>
<p>LoFTR：Detector-free Local Feature Matching with Transformers是一种detector-free的特征匹配算法，它不需要使用传统的特征检测器来提取局部特征点</p>
<h6 id="基于神经表示学习的三维场景重建"><a href="#基于神经表示学习的三维场景重建" class="headerlink" title="基于神经表示学习的三维场景重建"></a>基于神经表示学习的三维场景重建</h6><ul>
<li>重建流程：1. 比较渲染图像雨输入图像，计算误差。 2.通过梯度回传修改网络参数，优化隐式神经表示待解决问题：</li>
<li>隐式神经表示重建<strong>（采样）</strong>效率低下，难以扩展到大规模场景室内弱纹理区域缺乏足够约束，隐式神经表示重建成为病态话问题</li>
</ul>
<h6 id="杂"><a href="#杂" class="headerlink" title="杂"></a>杂</h6><p>Neural Reconsturction in the Wild</p>
<ul>
<li>核心思想：表面引导的层次化采样，基于互联网图像进行场景重建核心思想：平面先验</li>
</ul>
<p>基于神经表示学习的动态人体重建<br>    动态人体重建传统方案通过稠密相机阵列逐帧重建Neural Body<br>挑战：如何减少输入视点的数量<br>从稀疏的输入视图重建神经表示是病态问题</p>
<h6 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h6><p>核心思想：整合时序观测，假设不同时刻的观测来自于同一组隐编码</p>
<p>挑战：如何建模多人场景核心</p>
<p>思想：同步重建与分割</p>
<p>二维图像特征表示学习   -〉更鲁邦的图像匹配和位姿估计</p>
<p>三维几何&#x2F;外观表示学习 -〉更鲁棒更高质量的三维重建</p>
<p>NGP</p>
<h5 id="Nerf"><a href="#Nerf" class="headerlink" title="Nerf"></a>Nerf</h5><p><a href="https://yconquesty.github.io/blog/ml/nerf/">https://yconquesty.github.io/blog/ml/nerf/</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/631284285">https://zhuanlan.zhihu.com/p/631284285</a></p>
<p>NeRF,neural radiance field，翻译为神经辐射场</p>
<p><img src="https://pic2.zhimg.com/v2-6bf894d1fd88981551751cf4337b931d_b.jpg"></p>
<p>Instant-NGP的pipeline</p>
<p><img src="https://pic1.zhimg.com/v2-4e7016eb074496cf0235a7ff685d8c24_r.jpg"></p>
]]></content>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title>杂</title>
    <url>/2023/07/06/%E6%9D%82/</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/weixin_43863869/article/details/125002909">https://blog.csdn.net/weixin_43863869/article/details/125002909</a></p>
<ul>
<li><code>/etc/environment</code>：系统级环境变量文件，适用于所有用户和进程。</li>
<li><code>~/.bashrc</code>：登录shell级别的环境变量文件，适用于当前用户和其子进程。</li>
<li><code>~/.bash_profile</code>：登录shell级别的环境变量文件，仅适用于当前用户。</li>
<li><code>~/.profile</code>：登录shell级别的环境变量文件，仅适用于当前用户。</li>
</ul>
<p><a href="https://blog.csdn.net/weixin_45837114/article/details/128255248">https://blog.csdn.net/weixin_45837114/article/details/128255248</a></p>
<h6 id="合成视频"><a href="#合成视频" class="headerlink" title="合成视频"></a>合成视频</h6><pre><code>import cv2
import numpy as np

videoLeft = cv2.VideoCapture(&#39;C:\\Users\\USTC\\Desktop\\debug_pose\\PRED\\0000\\all_frame.mp4&#39;)
videoRight = cv2.VideoCapture(&#39;C:\\Users\\USTC\\Desktop\\debug_pose\\GT\\0000\\all_frame.mp4&#39;)

fps = videoLeft.get(cv2.CAP_PROP_FPS)

width = (int(videoLeft.get(cv2.CAP_PROP_FRAME_WIDTH)))
height = (int(videoLeft.get(cv2.CAP_PROP_FRAME_HEIGHT)))

videoWriter = cv2.VideoWriter(&#39;C:\\Users\\USTC\\Desktop\\debug_pose\\GT\\output.mp4&#39;, cv2.VideoWriter_fourcc(*&#39;mp4v&#39;), fps, (width*2, height))

successLeft, frameLeft = videoLeft.read()
successRight, frameRight = videoRight.read()

while successLeft and successRight:
    frameLeft = cv2.resize(frameLeft, (width, height), interpolation=cv2.INTER_CUBIC)
    frameRight = cv2.resize(frameRight, (width, height), interpolation=cv2.INTER_CUBIC)

    frame = np.hstack((frameLeft, frameRight))

    videoWriter.write(frame)

    successLeft, frameLeft = videoLeft.read()
    successRight, frameRight = videoRight.read()

videoWriter.release()
videoLeft.release()
videoRight.release()
</code></pre>
]]></content>
      <tags>
        <tag>杂</tag>
      </tags>
  </entry>
  <entry>
    <title>多GPU训练</title>
    <url>/2023/07/08/%E5%A4%9AGPU%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/157976140">https://zhuanlan.zhihu.com/p/157976140</a></p>
<h5 id="一机多卡训练"><a href="#一机多卡训练" class="headerlink" title="一机多卡训练"></a>一机多卡训练</h5><pre><code class="python">import torch.distributed
</code></pre>
<h6 id="初始化后端"><a href="#初始化后端" class="headerlink" title="初始化后端"></a>初始化后端</h6><pre><code class="python">local_rank = args.local_rank
torch.cuda.set_device(local_rank)
torch.distributed.init_process_group(backend=&#39;nccl&#39;, init_method=&#39;env://&#39;)
</code></pre>
<h6 id="模型并行化"><a href="#模型并行化" class="headerlink" title="模型并行化"></a>模型并行化</h6><pre><code class="python">model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank], output_device=local_rank)
</code></pre>
<h6 id="数据并行"><a href="#数据并行" class="headerlink" title="数据并行"></a>数据并行</h6><pre><code class="python">sampler = torch.utils.data.distributed.DistributedSampler(dataset)
rand_loader = DataLoader(dataset=dataset,batch_size=batch_size, shuffle=False, sampler=sampler)
</code></pre>
<h6 id="启动脚本"><a href="#启动脚本" class="headerlink" title="启动脚本"></a>启动脚本</h6><pre><code>python -m torch.distributed.launch --nproc_per_node=6 run_mvp_train_DDP_threepeople.py --overlap_slide
</code></pre>
<pre><code class="python">python -m torch.distributed.launch --nproc_per_node=8 train_face_troch.py
</code></pre>
<pre><code class="python">def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(&#39;--local_rank&#39;, default=0, type=int)
    args = parser.parse_args()
    return args
</code></pre>
<pre><code class="python">model, optimizer = amp.initialize(model, optimizer, opt_level=&#39;O1&#39;)  # 这里是字母O
</code></pre>
<pre><code class="python">if torch.cuda.is_available():
    model.cuda()
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>POSE</title>
    <url>/2023/07/13/POSE/</url>
    <content><![CDATA[<h5 id="RLE"><a href="#RLE" class="headerlink" title="RLE"></a>RLE</h5><p><a href="https://zhuanlan.zhihu.com/p/625023463">https://zhuanlan.zhihu.com/p/625023463</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/440567782">https://zhuanlan.zhihu.com/p/440567782</a></p>
<p><a href="https://github.com/Jeff-sjtu/res-loglikelihood-regression">https://github.com/Jeff-sjtu/res-loglikelihood-regression</a></p>
<p><a href="https://www.bilibili.com/video/BV18E411w7Jh/?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV18E411w7Jh/?spm_id_from=333.999.0.0</a> 讲flow的视频</p>
<p>GAN训练：模式崩溃和后置崩溃挑战</p>
<p><a href="https://zhuanlan.zhihu.com/p/165577850">https://zhuanlan.zhihu.com/p/165577850</a> flow的文章</p>
<p><a href="https://zhuanlan.zhihu.com/p/59615785">https://zhuanlan.zhihu.com/p/59615785</a> 讲flow的文章</p>
]]></content>
      <tags>
        <tag>pose</tag>
      </tags>
  </entry>
  <entry>
    <title>mmlab</title>
    <url>/2023/07/14/mmlab/</url>
    <content><![CDATA[<p><a href="https://github.com/open-mmlab/mmpose">https://github.com/open-mmlab/mmpose</a></p>
<p><a href="https://github.com/TommyZihao/MMPose_Tutorials">https://github.com/TommyZihao/MMPose_Tutorials</a></p>
<p><a href="https://github.com/open-mmlab/OpenMMLabCourse">https://github.com/open-mmlab/OpenMMLabCourse</a></p>
<h4 id="杂"><a href="#杂" class="headerlink" title="杂"></a>杂</h4><h6 id="修饰器"><a href="#修饰器" class="headerlink" title="修饰器"></a>修饰器</h6><p><a href="https://www.runoob.com/w3cnote/python-func-decorators.html">https://www.runoob.com/w3cnote/python-func-decorators.html</a></p>
<h6 id="args-kwargs-python解释"><a href="#args-kwargs-python解释" class="headerlink" title="*args, **kwargs python解释"></a>*args, **kwargs python解释</h6><p>*args用于接收任意数量的位置参数，它将所有传递给函数的位置参数打包成一个元组（tuple）。例如：</p>
<pre><code>def my_function(*args):
    for arg in args:
        print(arg)

my_function(1, 2, 3)  # 输出 1 2 3
</code></pre>
<p>**kwargs用于接收任意数量的关键字参数，它将所有传递给函数的关键字参数打包成一个字典（dict）。例如：</p>
<pre><code>def my_function(**kwargs):
    for key, value in kwargs.items():
        print(key, value)

my_function(name=&#39;Tom&#39;, age=20)  # 输出 name Tom  age 20
</code></pre>
<p><img src="/../images/mmlab/image-20230716001111023.png" alt="image-20230716001111023"></p>
<h4 id="基础介绍"><a href="#基础介绍" class="headerlink" title="基础介绍"></a>基础介绍</h4><p><strong>fileio、image、parallel、runner 和 utils 这几个非常通用的组件</strong></p>
<h5 id="fileio"><a href="#fileio" class="headerlink" title="fileio"></a><strong>fileio</strong></h5><h6 id="涉及文件读写的-FileHandler"><a href="#涉及文件读写的-FileHandler" class="headerlink" title="涉及文件读写的 FileHandler"></a>涉及文件读写的 FileHandler</h6><p>根据待读写的文件后缀名自动选择对应的 handler 进行具体操作</p>
<pre><code>mmcv/mmcv/fileio/handlers/base.py
</code></pre>
<h6 id="杂-1"><a href="#杂-1" class="headerlink" title="杂"></a>杂</h6><p>在Python中，如果要定义一个抽象类，需要使用abc模块。下面是一个使用@abstractmethod装饰器定义抽象方法的例子：</p>
<pre><code>from abc import ABC, abstractmethod

class MyAbstractClass(ABC):
    @abstractmethod
    def my_abstract_method(self):
        pass
</code></pre>
<p>自己写装饰器</p>
<p>先定义一个装饰器</p>
<pre><code>def my_decorator(func):
    def wrapper(*args, **kwargs):
        print(&#39;Before the function is called.&#39;)
        result = func(*args, **kwargs)
        print(&#39;After the function is called.&#39;)
        return result
    return wrapper
</code></pre>
<p>上面的代码定义了一个名为my_decorator的装饰器，它接受一个函数作为参数，并返回一个新的函数wrapper。wrapper函数在调用原函数之前和之后会打印一些信息，以增强原函数的功能。使用装饰器时，只需要在原函数前面加上@my_decorator即可将装饰器应用到原函数中，例如：</p>
<pre><code>@my_decorator
def my_function():
    print(&#39;This is my function.&#39;)
</code></pre>
<p>在上面的例子中，my_function函数被@my_decorator装饰器装饰，当调用my_function函数时，会先打印’Before the function is called.’，然后执行原函数的代码，最后打印’After the function is called.’。</p>
<h6 id="文件获取后端-FileClient"><a href="#文件获取后端-FileClient" class="headerlink" title="文件获取后端 FileClient"></a>文件获取后端 FileClient</h6><p>主要用于训练过程中数据的读取，通过用户选择或者自定义不同的 FileClient 后端，可以轻松实现文件缓存、文件加速读取等功能</p>
]]></content>
  </entry>
  <entry>
    <title>虚拟环境配置</title>
    <url>/2023/07/15/%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h5 id="likemmcv"><a href="#likemmcv" class="headerlink" title="likemmcv"></a>likemmcv</h5><p><a href="https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp39-cp39-linux_x86_64.whl">torch-1.12.0+cu113-cp39-cp39-linux_x86_64.whl</a></p>
<p>python 3.9</p>
<pre><code>mmcv==2.0.0
</code></pre>
<pre><code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu113
</code></pre>
<p>conda install cudnn&#x3D;8.9.0  -c <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/</a></p>
<pre><code class="shell">conda install cudnn=8.9.0 -c http://mirrors.aliyun.com/anaconda/pkgs/main
</code></pre>
]]></content>
      <tags>
        <tag>杂</tag>
      </tags>
  </entry>
</search>
